---
title: "Tecnologia e minorias"
excerpt: "As perversões nas interações entre sociedade e suas tecnologias"
date: 2017-09-05
customTags: ["Sociedade", "Tecnologia"]
type: "post"
draft: false
---

Nos últimos dois anos, somente brancos fora nominados para as categorias de atuação do Oscar, o que levou as hashcustomTags [#OscarSoWhite](https://twitter.com/hashtag/oscarsowhite) e [#OscarStillSoWhite](https://twitter.com/hashtag/oscarstillsowhite) ao trending no Twitter e promoveu um debate acalorado sobre o tema em redes sociais [^1]. A discussão parece ter tido resultado: em 2017, finalmente há negros em todas as principais categorias.

Os membros da Academia de Artes e Ciências Cinematográficas, organizadora do prêmio, no entanto, não são os únicos selecionadores com claro viés racial. Recentemente, um concurso mundial de beleza em que a seleção dos ganhadores ficou a cargo de uma inteligência artificial, o [Beauty.AI](http://beauty.ai/), publicou seus 44 ganhadores, dos quais apenas 1 não tinha pele clara e outros poucos eram asiáticos [^2], mesmo que grande parte de seus candidatos tenham vindo da Índia ou de países da África. Mas o que leva um software a ter preferências de cor de pele?

Para entender a resposta, é necessário saber como o robô em questão aprendeu a determinar a beleza das fotos que recebia. O algoritmo, que foi desenvolvido pelo grupo _Youth Laboratories_ com apoio da _Microsoft_, aprendeu a avaliar a beleza dos candidatos a partir de uma enorme quantidade de fotos de pessoas, cada uma associada a uma pontuação de beleza, a partir das quais o algoritmo ‘aprendia’ a calcular a pontuação de beleza a partir de um retrato qualquer. No entanto, Alex Zhavoronkov, CSO (_Chief Science Officer_) da Beauty.AI, afirmou que o problema foi ter exposto o sistema a uma imensa maioria de pessoas brancas. Portanto, o algoritmo apenas evidenciou o viés racial dos próprios organizadores da competição.

O aparente racismo (e outras formas de discriminação) de algumas de nossas tecnologias baseadas em aprendizado de máquina é aprendido com a nossa sociedade e seus preconceitos estruturais. Outro exemplo recente foi Tay, o bot desenvolvido pela Microsoft para entender a linguagem de adolescentes e soar como eles [^3].

{% figure "images/tweet-1.png" "Tweet de @Tayandyou com conteúdo antissemita" %}

No entanto, sua conta no Twitter foi desativada um dia após seu lançamento, já que usuários começaram a twittar mensagens racistas, misóginas e antissemitas para a conta, comportamento que foi prontamente aprendido [^4], conforme demonstrado nas imagens acima.

A questão da inadequação de tecnologias a pessoas não-brancas é antiga e data, pelo menos, da invenção dos _Shirley Cards_, utilizados para calibrar os esquemas de cores de filmes fotográficos entre as décadas de 40 e 90. Com eles, buscava-se representar com a maior precisão possível a _‘cor de pele’_  — obviamente baseada na pele branca.

{% figure "images/shirley-cards.gif" "Shirley cards, usados para estudar o esquema de cores de filmes analógicos" %}

Nestes cartões, apareciam algumas cores básicas e fotos de mulheres brancas com roupas coloridas, refletindo nisso o seu público alvo. Tal escolha levou, no entanto, a representações de pessoas negras ou de outras etnias com pouca precisão, confusas e borradas, conforme abaixo:

{% figure "images/kodak.png" "Fotografia com pessoas de pele escura, demonstrando a ineficácia de filmes da época em representar esse tom de pele" %}

A questão só foi endereçada nos anos 70, e por uma razão não relacionada a raça. Diferentes empresas passaram a questionar a precisão dos filmes fotográficos produzidos à época, ao reproduzir em fotografias as diferentes nuances de cor de seus produtos. Por exemplo, empresas de móveis não conseguiam mostrar a diferença entre os diferentes tipos de madeira, e chocolate ao leite e chocolate meio amargo eram difíceis de distinguir em anúncios impressos.

Para saber mais sobre o assunto, assista ao vídeo que a Vox fez sobre o assunto:

<iframe
	width="640"
	height="360"
	src="https://www.youtube.com/embed/d16LNHIEJzs"
	frameborder="0"
	allow="autoplay; encrypted-media"
	allowfullscreen
></iframe>

Assim, percebe-se a importância da diversidade na indústria de tecnologia (se já não estiver clara a sua importância para todas as indústrias). Com equipes mais diversas, os produtos são testados em casos que representam uma maior quantidade de pessoas — e, principalmente, perfis mais variados. Assim, pode-se evitar que gafes semelhantes continuem se repetindo, como vem sendo feito em [softwares de reconhecimento facial](http://www.huffpostbrasil.com/entry/heres-why-facial-recognition-tech-cant-figure-out-black-people_us_56d5c2b1e4b0bf0dab3371eb). Isso, no entanto, não surpreende, já que mulheres e minorias étnicas continuam sendo sub-representados em empresas de tecnologia dos EUA, com hispânicos ocupando 8% dos cargos; negros, 7%; e mulheres, 33%. E as proporções pioram quando os cargos sobem na hierarquia [^5].

E é por isso e por outras tantas razões que representatividade e diversidade no ambiente de trabalho contam!

[^1]: [ Oscar 2016: atores negros estão ausentes pelo 2º ano seguido](http://g1.globo.com/pop-arte/oscar/2016/noticia/2016/01/oscar-nao-indica-nenhum-ator-negro-ao-pelo-segundo-ano-consecutivo.html)
[^2]: [A beauty contest was judged by AI and the robots didn’t like dark skin](https://www.theguardian.com/technology/2016/sep/08/artificial-intelligence-beauty-contest-doesnt-like-black-people)
[^3]: [Microsoft made a chatbot that tweets like a teen](http://www.theverge.com/2016/3/23/11290200/tay-ai-chatbot-released-microsoft)
[^4]: [Twitter taught Microsoft’s AI chatbot to be a racist asshole in less than a day](http://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist)
[^5]: [ Why Diversity Matters In Tech](http://www.forbes.com/sites/mnewlands/2016/08/29/why-diversity-matters-in-tech/#2a51d01f3a12)
